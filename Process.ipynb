{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f21cd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringType\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     Tokenizer,\n\u001b[32m      9\u001b[39m     StopWordsRemover,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     VectorAssembler,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Fonction 1 : nettoyage du texte\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MiniProjet-8INF919/.venv/lib/python3.12/site-packages/pyspark/ml/__init__.py:31\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     Estimator,\n\u001b[32m     24\u001b[39m     Model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     UnaryTransformer,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline, PipelineModel\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     classification,\n\u001b[32m     33\u001b[39m     clustering,\n\u001b[32m     34\u001b[39m     evaluation,\n\u001b[32m     35\u001b[39m     feature,\n\u001b[32m     36\u001b[39m     fpm,\n\u001b[32m     37\u001b[39m     image,\n\u001b[32m     38\u001b[39m     recommendation,\n\u001b[32m     39\u001b[39m     regression,\n\u001b[32m     40\u001b[39m     stat,\n\u001b[32m     41\u001b[39m     tuning,\n\u001b[32m     42\u001b[39m     util,\n\u001b[32m     43\u001b[39m     linalg,\n\u001b[32m     44\u001b[39m     param,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchDistributor\n\u001b[32m     48\u001b[39m __all__ = [\n\u001b[32m     49\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTransformer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUnaryTransformer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTorchDistributor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MiniProjet-8INF919/.venv/lib/python3.12/site-packages/pyspark/ml/image.py:31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, NoReturn, Optional, cast\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdistutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Row, StructType, _create_row, _parse_datatype_json_string\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer,\n",
    "    StopWordsRemover,\n",
    "    NGram,\n",
    "    HashingTF,\n",
    "    VectorAssembler,\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Fonction 1 : nettoyage du texte\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def clean_text_column(df, text_col=\"text\", output_col=\"clean_text\"):\n",
    "    \"\"\"\n",
    "    Nettoie une colonne de texte :\n",
    "    - minuscules\n",
    "    - suppression URL\n",
    "    - suppression caractères non alphabétiques\n",
    "    - réduction espaces\n",
    "    \"\"\"\n",
    "\n",
    "    col = F.lower(F.col(text_col))\n",
    "    col = F.regexp_replace(col, r\"http\\S+|www\\.\\S+\", \" \")\n",
    "    col = F.regexp_replace(col, r\"[^a-z\\s]\", \" \")\n",
    "    col = F.regexp_replace(col, r\"\\s+\", \" \")\n",
    "    col = F.trim(col)\n",
    "\n",
    "    return df.withColumn(output_col, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f13d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(num_features=262144):\n",
    "    \"\"\"\n",
    "    Pipeline Spark :\n",
    "    1. Tokenizer\n",
    "    2. StopWordsRemover\n",
    "    3. NGram (2-gram)\n",
    "    4. HashingTF sur unigrams\n",
    "    5. HashingTF sur bigrams\n",
    "    6. VectorAssembler -> features\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = Tokenizer(\n",
    "        inputCol=\"clean_text\",\n",
    "        outputCol=\"tokens\"\n",
    "    )\n",
    "\n",
    "    remover = StopWordsRemover(\n",
    "        inputCol=\"tokens\",\n",
    "        outputCol=\"unigrams\"\n",
    "    )\n",
    "\n",
    "    bigrammer = NGram(\n",
    "        n=2,\n",
    "        inputCol=\"unigrams\",\n",
    "        outputCol=\"bigrams\"\n",
    "    )\n",
    "\n",
    "    hashing_unigrams = HashingTF(\n",
    "        numFeatures=num_features,\n",
    "        inputCol=\"unigrams\",\n",
    "        outputCol=\"unigram_features\"\n",
    "    )\n",
    "\n",
    "    hashing_bigrams = HashingTF(\n",
    "        numFeatures=num_features,\n",
    "        inputCol=\"bigrams\",\n",
    "        outputCol=\"bigram_features\"\n",
    "    )\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"unigram_features\", \"bigram_features\"],\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[\n",
    "        tokenizer,\n",
    "        remover,\n",
    "        bigrammer,\n",
    "        hashing_unigrams,\n",
    "        hashing_bigrams,\n",
    "        assembler\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de PySpark : 4.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"Version de PySpark :\", pyspark.__version__)\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[*]\")  # ⚠️ TRÈS IMPORTANT : on force Spark à tourner en local\n",
    "    .appName(\"Test_Spark_Minimal\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "print(\"SparkContext master :\", spark.sparkContext.master)\n",
    "print(\"Spark version :\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99595af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"./train.csv\"   # à adapter\n",
    "path_output = \"./train_parquet_notebook\"   # dossier de sortie\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(path_train)\n",
    ")\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "\n",
    "print(\"✓ CSV chargé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ee6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    F.col(\"sentiment\").alias(\"label\"),\n",
    "    F.col(\"text\").cast(StringType())\n",
    ").dropna(subset=[\"label\", \"text\"])\n",
    "\n",
    "df.show(5)\n",
    "print(\"Nombre de lignes :\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd49e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_text_column(df, text_col=\"text\", output_col=\"clean_text\")\n",
    "\n",
    "df_clean.select(\"text\", \"clean_text\").show(10, truncate=False)\n",
    "print(\"✓ Texte nettoyé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = build_pipeline(num_features=262144)\n",
    "print(\"✓ Pipeline créé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"⏳ Entraînement du pipeline...\")\n",
    "model = pipeline.fit(df_clean)\n",
    "\n",
    "print(\"⏳ Transformation...\")\n",
    "df_final = model.transform(df_clean)\n",
    "\n",
    "df_final.select(\"label\", \"features\").show(5, truncate=False)\n",
    "\n",
    "print(\"✓ Transformation terminée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"⏳ Entraînement du pipeline...\")\n",
    "model = pipeline.fit(df_clean)\n",
    "\n",
    "print(\"⏳ Transformation...\")\n",
    "df_final = model.transform(df_clean)\n",
    "\n",
    "df_final.select(\"label\", \"features\").show(5, truncate=False)\n",
    "\n",
    "print(\"✓ Transformation terminée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"✓ Spark arrêté\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e2393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
